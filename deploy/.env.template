# =============================================================================
# YAGMCP Server Configuration
# Copy to .env and adjust values for your environment.
# =============================================================================

TZ=America/New_York

# Ollama LLM backend
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5-coder:7b
# Per-call read timeout for Ollama requests (seconds).
# Increase for large models (20B+) that take >180s with big context payloads.
OLLAMA_TIMEOUT=300

# Ghidra repos (mounted volume)
REPOS_DIR=/repos

# Project cache
MAX_CACHED_PROGRAMS=5

# Server
GHIDRA_ASSIST_PORT=8889
LOG_LEVEL=INFO
